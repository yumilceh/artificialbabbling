{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Created on October 31st 2017\n",
    "@author: Juan Manuel Acevedo Valle\n",
    "''' \n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import h5py, os, sys, random\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy import stats\n",
    "from scipy.stats.distributions import norm    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import itertools\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from scipy.stats import pearsonr, shapiro, anderson\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "colors_ = ['firebrick', 'darkgreen', 'navy', 'm', 'deepskyblue', 'goldenrod', 'black', 'grey']\n",
    "\n",
    "from SensorimotorExploration.DataManager.SimulationData import load_sim_h5_v2 as load_sim_h5\n",
    "from SensorimotorExploration.DataManager.PlotTools import *\n",
    "from results_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0_93&social\n",
      "The shape of the data for PCA is:\n",
      "(11016010L, 6L)\n",
      "Variance contribution per per principal axes: \n",
      "[ 0.66268865  0.60899833  0.01984912  0.01444376]\n",
      "% Variance contribution per per principal axes: \n",
      "[ 0.50742639  0.46631525  0.01519864  0.01105971]\n",
      "Principal directions [n_components_n_features]:\n",
      "[[ 0.2428291   0.26484068  0.5798645   0.73119806]\n",
      " [ 0.6081615   0.70773244 -0.20947987 -0.29218583]\n",
      " [-0.05201656  0.06651423 -0.7840338   0.61494807]\n",
      " [-0.7539681   0.65157506  0.07187721 -0.04261121]]\n"
     ]
    }
   ],
   "source": [
    "directories = {\n",
    "               50: 'diva_IEEE_SI/experiment_IEEE_SI_slopes_cmf_050/',\n",
    "               123: 'diva_IEEE_SI/experiment_IEEE_SI_slopes_cmf_123/',\n",
    "               223: 'diva_IEEE_SI/experiment_IEEE_SI_slopes_cmf_223/',\n",
    "               #323: 'diva_IEEE_SI/experiment_IEEE_SI_slopes_cmf_323/'\n",
    "              }\n",
    "\n",
    "besties = {\n",
    "               50: '0.99',\n",
    "               123: '0.99',\n",
    "               223: '0.99',\n",
    "               #323: '0.99'\n",
    "              }\n",
    "\n",
    "data_files = []\n",
    "for key in directories.keys():\n",
    "    data_files += [directories[key] + file_ for file_ in os.listdir(directories[key])]\n",
    "\n",
    "n_samples = 102000\n",
    "# Group by:\n",
    "alpha_social_thresh = ['1_0', '0_999999', '0_99', '0_96', '0_93']\n",
    "mode_ops = ['social']\n",
    "\n",
    "groups1 = itertools.product(alpha_social_thresh, mode_ops)\n",
    "groups2 = itertools.product(['1'], ['autonomous'])\n",
    "\n",
    "groups_k =  list(groups2) + list(groups1)\n",
    "\n",
    "for data_file in (d_f for d_f in data_files if 'sim_data.h5' in d_f):\n",
    "    data_file = data_file\n",
    "    conf_file = data_file.replace('sim_data.h5', 'conf.txt')\n",
    "    conf = {}\n",
    "    with open(conf_file) as f:\n",
    "        for line in f:\n",
    "            line = line.replace('\\n', '')\n",
    "            (key, val) = line.split(': ')\n",
    "            conf[key] = val\n",
    "    data,foo = load_sim_h5(data_file)\n",
    "    try:\n",
    "        concat_sensor = np.append(concat_sensor, data.sensor.data.as_matrix(), axis=0)\n",
    "#         print \"Appending\"\n",
    "    except:\n",
    "        concat_sensor = data.sensor.data.as_matrix()\n",
    "#         print \"First set\"\n",
    "\n",
    "print('Processing ' + group)\n",
    "print(\"The shape of the data for PCA is:\")\n",
    "print(concat_sensor.shape)\n",
    "pca = PCA(n_components = 4)      \n",
    "pca.fit(concat_sensor[:,[0,1,3,4]])\n",
    "print(\"Variance contribution per per principal axes: \")\n",
    "print(str(pca.explained_variance_))    \n",
    "print(\"% Variance contribution per per principal axes: \")\n",
    "print( str(pca.explained_variance_ratio_))    \n",
    "print(\"Principal directions [n_components_n_features]:\")\n",
    "print(pca.components_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py, random\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.stats.distributions import norm    \n",
    "\n",
    "def plotPDFx_y(axes, data, color):\n",
    "    if len(directories)==0:\n",
    "        return  \n",
    "    x_grid = np.linspace(-3.0, 3., 500)\n",
    "    y_grid = np.linspace(-3.0, 3., 500)\n",
    "    \n",
    "    sensor_data = pca.transform(sensor_data)\n",
    "    \n",
    "    # The grid we'll use for plotting\n",
    "\n",
    "    #------ kde = gaussian_kde(x, bw_method=bandwidth / x.std(ddof=1), **kwargs) \n",
    "    # Note that scipy weights its bandwidth by the covariance of the\n",
    "    # input data.  To make the results comparable to the other methods,\n",
    "    # we divide the bandwidth by the sample standard deviation here.\n",
    "\n",
    "    # pdf = gaussian_kde(sensor_data1[:,0], bw_method=0.02/  sensor_data1[:,0].std(ddof=1)).evaluate(x_grid)\n",
    "    kde_x = gaussian_kde(sensor_data[:,0])\n",
    "    pdf_x = kde_x.evaluate(x_grid)\n",
    "    axes[0].plot(x_grid, pdf_x, color=color, alpha=0.5, lw=3)\n",
    "    axes[0].set_xlim(-1.0, 1.5)\n",
    "    \n",
    "    # pdf = gaussian_kde(sensor_data1[:,1], bw_method=0.02 / sensor_data1[:,1].std(ddof=1)).evaluate(y_grid)\n",
    "    kde_y = gaussian_kde(sensor_data[:,1])\n",
    "    pdf_y = kde_y.evaluate(y_grid)\n",
    "    axes[1].plot(y_grid, pdf_y, color=color, alpha=0.5, lw=3)\n",
    "    axes[1].set_xlim(-1.0, 1.5)\n",
    "    \n",
    "    tmp_dict = {'KDEx_' + directory: kde_x, 'KDEy_' + directory: kde_y, 'PDFx_' + directory: pdf_x, 'PDFy_' + directory: pdf_y }\n",
    "    return tmp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_used = 'euclidean'\n",
    "sensor_data = None\n",
    "\n",
    "for key in directories.keys(): # for key, color in zip(error_ev_av.keys(), colors_):\n",
    "    data_files = [directories[key] + file_ for file_ in os.listdir(directories[key])]\n",
    "    for data_file in (d_f for d_f in data_files if 'sim_data.h5' in d_f):\n",
    "    data_file = data_file\n",
    "    conf_file = data_file.replace('sim_data.h5', 'conf.txt')\n",
    "    conf = {}\n",
    "    with open(conf_file) as f:\n",
    "        for line in f:\n",
    "            line = line.replace('\\n', '')\n",
    "            (key_, val) = line.split(': ')\n",
    "            conf[key_] = val\n",
    "    data,foo = load_sim_h5(data_file)\n",
    "    if conf['instructor_slope']==besties[key]  and conf['mode']=='social':\n",
    "        try:\n",
    "            concat_sensor_s = np.append(concat_sensor_s, data.sensor.data.as_matrix(), axis=0)\n",
    "        except:\n",
    "            concat_sensor_s = data.sensor.data.as_matrix()\n",
    "#     elif conf['mode']=='autonomous':\n",
    "#         try:\n",
    "#             concat_sensor_a = np.append(concat_sensor_a, data.sensor.data.as_matrix(), axis=0)\n",
    "#         except:\n",
    "#             concat_sensor_a = data.sensor.data.as_matrix()    \n",
    "    plotPDFx_y(axes, data, 'blue')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1&autonomous\n",
      "The shape of the data for PCA is:\n",
      "(612000L, 6L)\n",
      "Variance contribution per per principal axes: \n",
      "[ 0.7836967   0.4732139   0.0159805   0.01236824]\n",
      "% Variance contribution per per principal axes: \n",
      "[ 0.60975764  0.36818554  0.01243368  0.00962315]\n",
      "Principal directions [n_components_n_features]:\n",
      "[[ 0.37422021  0.46340741 -0.48873288 -0.63745821]\n",
      " [ 0.51703424  0.61479868  0.3636756   0.47163359]\n",
      " [ 0.03173144 -0.02458514 -0.79259282  0.60842856]\n",
      " [-0.76917355  0.63770818 -0.02601636  0.03199184]]\n",
      "Processing 1_0&social\n",
      "The shape of the data for PCA is:\n",
      "(612001L, 6L)\n",
      "Variance contribution per per principal axes: \n",
      "[ 0.71878886  0.51541238  0.02178916  0.01676677]\n",
      "% Variance contribution per per principal axes: \n",
      "[ 0.56474941  0.40495736  0.01711965  0.01317358]\n",
      "Principal directions [n_components_n_features]:\n",
      "[[ 0.50401161  0.56071837  0.41066964  0.51275497]\n",
      " [ 0.42498987  0.50093242 -0.45354636 -0.602284  ]\n",
      " [ 0.05247949 -0.06560608  0.78750226 -0.61055871]\n",
      " [-0.75006787  0.65601636  0.0740698  -0.03942571]]\n",
      "Processing 0_999999&social\n",
      "The shape of the data for PCA is:\n",
      "(612001L, 6L)\n",
      "Variance contribution per per principal axes: \n",
      "[ 0.71878886  0.51541238  0.02178916  0.01676677]\n",
      "% Variance contribution per per principal axes: \n",
      "[ 0.56474941  0.40495736  0.01711965  0.01317358]\n",
      "Principal directions [n_components_n_features]:\n",
      "[[ 0.50401161  0.56071837  0.41066964  0.51275497]\n",
      " [ 0.42498987  0.50093242 -0.45354636 -0.602284  ]\n",
      " [ 0.05247949 -0.06560608  0.78750226 -0.61055871]\n",
      " [-0.75006787  0.65601636  0.0740698  -0.03942571]]\n",
      "Processing 0_99&social\n",
      "The shape of the data for PCA is:\n",
      "(612000L, 6L)\n",
      "Variance contribution per per principal axes: \n",
      "[ 0.70593455  0.52135746  0.02802877  0.01478963]\n",
      "% Variance contribution per per principal axes: \n",
      "[ 0.55580566  0.410482    0.02206798  0.01164436]\n",
      "Principal directions [n_components_n_features]:\n",
      "[[ 0.47280135  0.52775755  0.46436333  0.53131681]\n",
      " [ 0.46180285  0.53171495 -0.41751625 -0.57419293]\n",
      " [-0.08141044  0.13090797 -0.77177175  0.61693096]\n",
      " [-0.74603576  0.64931832  0.12006353 -0.08602973]]\n",
      "Processing 0_96&social\n",
      "The shape of the data for PCA is:\n",
      "(612000L, 6L)\n",
      "Variance contribution per per principal axes: \n",
      "[ 0.6534743   0.57025469  0.01941501  0.01149947]\n",
      "% Variance contribution per per principal axes: \n",
      "[ 0.52084462  0.45451533  0.01547452  0.00916553]\n",
      "Principal directions [n_components_n_features]:\n",
      "[[-0.34924648 -0.41494495  0.49662892  0.67764836]\n",
      " [ 0.550755    0.63430517  0.33484325  0.4268558 ]\n",
      " [ 0.02710398 -0.04297531  0.79961438 -0.59836055]\n",
      " [-0.75760227  0.65086924  0.04308781 -0.02348368]]\n",
      "Processing 0_93&social\n",
      "The shape of the data for PCA is:\n",
      "(612000L, 6L)\n",
      "Variance contribution per per principal axes: \n",
      "[ 0.66888039  0.49553255  0.02268596  0.00959495]\n",
      "% Variance contribution per per principal axes: \n",
      "[ 0.55894027  0.41408465  0.0189572   0.00801788]\n",
      "Principal directions [n_components_n_features]:\n",
      "[[ -6.51395870e-02  -7.99535599e-02   6.17632167e-01   7.79676067e-01]\n",
      " [  6.46937962e-01   7.55492306e-01   7.07598079e-02   7.54698523e-02]\n",
      " [  1.24932964e-02   5.70294179e-04  -7.83257553e-01   6.21571554e-01]\n",
      " [ -7.59652569e-01   6.50260316e-01  -5.58224552e-03   7.63771931e-03]]\n"
     ]
    }
   ],
   "source": [
    "directory = 'diva_IEEE_SI/experiment_IEEE_SI_slopes_cmf_223/'\n",
    "data_files = os.listdir(directory)\n",
    "\n",
    "n_samples = 102000\n",
    "# Group by:\n",
    "alpha_social_thresh = ['1_0', '0_999999', '0_99', '0_96', '0_93']\n",
    "mode_ops = ['social']\n",
    "\n",
    "groups1 = itertools.product(alpha_social_thresh, mode_ops)\n",
    "groups2 = itertools.product(['1'], ['autonomous'])\n",
    "\n",
    "groups_k =  list(groups2) + list(groups1)\n",
    "\n",
    "concat_sensor = create_dict(groups_k)\n",
    "\n",
    "for data_file in (d_f for d_f in data_files if 'sim_data.h5' in d_f):\n",
    "    data_file = directory + data_file\n",
    "    conf_file = data_file.replace('sim_data.h5', 'conf.txt')\n",
    "    conf = {}\n",
    "    with open(conf_file) as f:\n",
    "        for line in f:\n",
    "            line = line.replace('\\n', '')\n",
    "            (key, val) = line.split(': ')\n",
    "            conf[key] = val\n",
    "    if conf['mode'] == 'autonomous':\n",
    "        conf['instructor_slope'] = '1'\n",
    "    else:\n",
    "        conf['instructor_slope'] = conf['instructor_slope'].replace('.','_')\n",
    "            \n",
    "\n",
    "    data,foo = load_sim_h5(data_file)\n",
    "    try:\n",
    "        key = conf['instructor_slope'] + '&' + conf['mode']\n",
    "        concat_sensor[key] = np.append(concat_sensor[key], data.sensor.data.as_matrix(), axis=0)\n",
    "#         print \"Appending\"\n",
    "    except:\n",
    "        concat_sensor[key] = data.sensor.data.as_matrix()\n",
    "#         print \"First set\"\n",
    "\n",
    "for i, k in enumerate(groups_k):\n",
    "    group = k[0] + '&' + k[1] \n",
    "    print('Processing ' + group)\n",
    "    print(\"The shape of the data for PCA is:\")\n",
    "    print(concat_sensor[group].shape)\n",
    "    pca = PCA(n_components = 4)      \n",
    "    pca.fit(concat_sensor[group][:,[0,1,3,4]])\n",
    "    print(\"Variance contribution per per principal axes: \")\n",
    "    print(str(pca.explained_variance_))    \n",
    "    print(\"% Variance contribution per per principal axes: \")\n",
    "    print( str(pca.explained_variance_ratio_))    \n",
    "    print(\"Principal directions [n_components_n_features]:\")\n",
    "    print(pca.components_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'diva_IEEE_SI/experiment_IEEE_SI_slopes_cmf_050/'\n",
    "\n",
    " print(\"Loading data for PCA...\")\n",
    "    sensor_data = None\n",
    "    for i in range(len(directories)): \n",
    "        directory = directories[i]\n",
    "        mat = h5py.File(directory + 'SMdata.mat','r')\n",
    "        data = np.array(mat.get('SMdata'))\n",
    "        mat = h5py.File(directory + 'PRdata.mat','r')\n",
    "        proprio_data = np.array(mat.get('PRdata'))\n",
    "        proprio_data = proprio_data[[-1],:]\n",
    "        try:\n",
    "            sensor_data_tmp = np.transpose(data[[0,1,3,4],:])\n",
    "            sensor_data_tmp = sensor_data_tmp[np.where(proprio_data  < proprio_criteria)[1],:]\n",
    "            sensor_data = np.append(sensor_data,sensor_data_tmp,axis=0)\n",
    "        except:\n",
    "            sensor_data = np.transpose(data[[0,1,3,4],:])\n",
    "            sensor_data = sensor_data[np.where(proprio_data < proprio_criteria)[1],:]\n",
    "\n",
    "    pca =PCA(n_components=1)      \n",
    "    pca.fit(sensor_data)\n",
    "    print(\"The shape of the data for PCA is:\")\n",
    "    print(sensor_data.shape)\n",
    "    print(\"Variance contribution per per principal axes: \")\n",
    "    print(str(pca.explained_variance_))    \n",
    "    print(\"% Variance contribution per per principal axes: \")\n",
    "    print( str(pca.explained_variance_ratio_))    \n",
    "    print(\"Principal directions [n_components_n_features]:\")\n",
    "    print(pca.components_)\n",
    "    \n",
    "    del(data)\n",
    "    del(sensor_data)\n",
    "    del(sensor_data_tmp)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
